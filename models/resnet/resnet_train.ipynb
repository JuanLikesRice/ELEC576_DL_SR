{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Turog\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\cuda\\memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms.functional import resize\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import pad, resize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SuperResolutionDataset(Dataset):\n",
    "    def __init__(self, root_dir, patch_size=128, scale_factor=4, max_patches=16):\n",
    "        self.root_dir = root_dir\n",
    "        self.patch_size = patch_size\n",
    "        self.lr_patch_size = patch_size // scale_factor\n",
    "        self.image_list = os.listdir(root_dir)\n",
    "        self.scale_factor = scale_factor\n",
    "        self.max_patches = max_patches  \n",
    "        self.normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_list[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        width, height = image.size\n",
    "\n",
    "        # Split image into patches\n",
    "        hr_patches = []\n",
    "        lr_patches = []\n",
    "        for y in range(0, height, self.patch_size):\n",
    "            for x in range(0, width, self.patch_size):\n",
    "                hr_patch = image.crop((x, y, x + self.patch_size, y + self.patch_size))\n",
    "\n",
    "                # Skip incomplete patches\n",
    "                if hr_patch.size[0] != self.patch_size or hr_patch.size[1] != self.patch_size:\n",
    "                    continue\n",
    "                lr_patch = resize(hr_patch, (self.lr_patch_size, self.lr_patch_size), interpolation=Image.BILINEAR)\n",
    "                hr_patches.append(self.normalize(transforms.ToTensor()(hr_patch)))\n",
    "                lr_patches.append(self.normalize(transforms.ToTensor()(lr_patch)))\n",
    "\n",
    "        # Pad to max_patches\n",
    "        while len(hr_patches) < self.max_patches:\n",
    "            hr_patches.append(torch.zeros((3, self.patch_size, self.patch_size)))\n",
    "            lr_patches.append(torch.zeros((3, self.lr_patch_size, self.lr_patch_size)))\n",
    "\n",
    "        hr_patches = hr_patches[:self.max_patches]\n",
    "        lr_patches = lr_patches[:self.max_patches]\n",
    "\n",
    "        if len(hr_patches) == 0 or len(lr_patches) == 0:\n",
    "            raise ValueError(f\"No valid patches for image {img_path}\")\n",
    "\n",
    "        return torch.stack(lr_patches), torch.stack(hr_patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from torchvision.models import vgg16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class ResNetSuperResolution(nn.Module):\n",
    "    def __init__(self, upscale_factor=4):\n",
    "        super(ResNetSuperResolution, self).__init__()\n",
    "        \n",
    "        self.vgg_features = vgg16(pretrained=True).features[:8].eval()  \n",
    "        for param in self.vgg_features.parameters():\n",
    "            param.requires_grad = False \n",
    "\n",
    "        self.vgg_features.to(device) \n",
    "\n",
    "        self.channel_reducer = nn.Conv2d(128, 64, kernel_size=1)  \n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)  \n",
    "\n",
    "        self.conv1 = nn.Conv2d(64, 64, kernel_size=9, padding=4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.residual_blocks = nn.Sequential(*[\n",
    "            self._make_residual_block(64) for _ in range(5)\n",
    "        ])\n",
    "        \n",
    "        self.upsample1 = nn.Conv2d(64, 64 * (upscale_factor ** 2), kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.conv2 = nn.Conv2d(64, 3, kernel_size=9, padding=4)\n",
    "\n",
    "    def _make_residual_block(self, channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():  \n",
    "            x = self.vgg_features(x)\n",
    "\n",
    "        x = self.channel_reducer(x) \n",
    "        x = self.upsample(x)  \n",
    "        x = self.relu(self.conv1(x))\n",
    "        residual = x\n",
    "        x = self.residual_blocks(x)\n",
    "        x += residual  \n",
    "        x = self.pixel_shuffle(self.upsample1(x)) \n",
    "        x = self.conv2(x) \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def superres_loss(output, target):\n",
    "    return F.l1_loss(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r\"C:\\Users\\Turog\\OneDrive\\Documents\\GitHub\\576_DL_SuperRes\\data\\combined_largest_images_rd\"\n",
    "patch_size = 256\n",
    "scale_factor = 2\n",
    "dataset = SuperResolutionDataset(root_dir=root_dir, patch_size=patch_size, scale_factor=scale_factor)\n",
    "dataloader = DataLoader(dataset, batch_size=3, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Turog\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Turog\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "upscale_factor = scale_factor\n",
    "model = ResNetSuperResolution(upscale_factor)\n",
    "criterion = superres_loss\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "from torch.optim import RMSprop\n",
    "optimizer = RMSprop(model.parameters(), lr=1e-4, alpha=0.9, weight_decay=1e-5)\n",
    "\n",
    "os.makedirs(\"chkt_resnet_v9\", exist_ok=True) \n",
    "os.makedirs(\"progress_resnet_v9\", exist_ok=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.00 GB\n",
      "Memory reserved: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated(0)/1024**3:.2f} GB\")\n",
    "    print(f\"Memory reserved: {torch.cuda.memory_reserved(0)/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image, patch_size):\n",
    "    width, height = image.size\n",
    "    pad_width = (patch_size - width % patch_size) % patch_size\n",
    "    pad_height = (patch_size - height % patch_size) % patch_size\n",
    "    padding = (0, 0, pad_width, pad_height)\n",
    "    padded_image = pad(image, padding, fill=0)\n",
    "    return padded_image, padding\n",
    "\n",
    "\n",
    "def denormalize(tensor):\n",
    "    denorm = transforms.Normalize(mean=[-1, -1, -1], std=[2, 2, 2])  \n",
    "    return denorm(tensor)\n",
    "\n",
    "test_image_path =     r\"C:\\Users\\Turog\\OneDrive\\Documents\\GitHub\\576_DL_SuperRes\\data\\DIV2K\\0745.png\"\n",
    "test_image = Image.open(test_image_path).convert(\"RGB\")\n",
    "test_width, test_height = test_image.size\n",
    "padded_test_image, padding = pad_image(test_image, patch_size)\n",
    "padded_width, padded_height = padded_test_image.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.00 GB\n",
      "Memory reserved: 0.00 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 267/267 [14:43<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2611\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.09 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 267/267 [14:05<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.1649\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 267/267 [13:55<00:00,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.1384\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 267/267 [14:12<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.1255\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 267/267 [13:24<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.1169\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 267/267 [13:47<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.1102\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 267/267 [13:50<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.1053\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 267/267 [14:19<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.1016\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 267/267 [14:05<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.0990\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 267/267 [14:24<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.0961\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 267/267 [14:03<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.0942\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 267/267 [14:03<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.0920\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 267/267 [14:20<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.0905\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 267/267 [14:14<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.0890\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 267/267 [14:18<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.0876\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 267/267 [14:07<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.0864\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 267/267 [13:35<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.0853\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 267/267 [13:40<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.0848\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 267/267 [14:12<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.0834\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.06 GB\n",
      "Memory reserved: 7.10 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 267/267 [14:14<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.0824\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "def denormalize(tensor):  \n",
    "    return tensor * 0.5 + 0.5  \n",
    "\n",
    "os.makedirs(\"chkt_resnet_v9\", exist_ok=True)\n",
    "os.makedirs(\"progress_resnet_v9\", exist_ok=True)\n",
    "\n",
    "num_epochs = 20\n",
    "loss_values = []\n",
    "lr_patch_size = patch_size // scale_factor\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    if device.type == \"cuda\":\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "        print(f\"Memory allocated: {torch.cuda.memory_allocated(0)/1024**3:.2f} GB\")\n",
    "        print(f\"Memory reserved: {torch.cuda.memory_reserved(0)/1024**3:.2f} GB\")\n",
    "    \n",
    "    # Training loop\n",
    "    for lr_patches, hr_patches in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "            lr_patches = lr_patches.cuda()\n",
    "            hr_patches = hr_patches.cuda()\n",
    "\n",
    "        lr_patches = lr_patches.view(-1, 3, lr_patch_size, lr_patch_size)\n",
    "        hr_patches = hr_patches.view(-1, 3, patch_size, patch_size)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(lr_patches)\n",
    "        loss = criterion(outputs, hr_patches)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    loss_values.append(epoch_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"chkt_resnet_v9/superres_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    model.eval()\n",
    "    sr_test_patches = []\n",
    "    with torch.no_grad():\n",
    "        for patch in test_patches:\n",
    "            patch = patch.to(device)\n",
    "            output = model(patch)\n",
    "            sr_test_patches.append(denormalize(output).squeeze(0).cpu()) \n",
    "\n",
    "    sr_test_image = torch.zeros((3, padded_height, padded_width)) \n",
    "    patch_idx = 0\n",
    "    for y in range(0, padded_height, patch_size):\n",
    "        for x in range(0, padded_width, patch_size):\n",
    "            sr_test_image[:, y:y+patch_size, x:x+patch_size] = sr_test_patches[patch_idx]\n",
    "            patch_idx += 1\n",
    "\n",
    "    sr_test_image = sr_test_image[:, :test_height, :test_width]\n",
    "\n",
    "    patch_idx = 0 \n",
    "    low_res_patch = denormalize(test_patches[patch_idx].squeeze(0).cpu()) \n",
    "    super_res_patch = sr_test_patches[patch_idx]\n",
    "    high_res_patch = denormalize(transforms.ToTensor()(padded_test_image.crop((0, 0, patch_size, patch_size))))  \n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Low-Resolution Patch\")\n",
    "    plt.imshow(transforms.ToPILImage()(low_res_patch))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(f\"Super-Resolved Patch (Epoch {epoch+1})\")\n",
    "    plt.imshow(transforms.ToPILImage()(super_res_patch))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"High-Resolution Patch\")\n",
    "    plt.imshow(transforms.ToPILImage()(high_res_patch))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"progress_resnet_v9/epoch_{epoch+1}_patch_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()  \n",
    "\n",
    "    # Plot loss curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(loss_values) + 1), loss_values, marker='o', label=\"Training Loss\")\n",
    "    plt.title(\"Training Loss Over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"progress_resnet_v9/loss_plot.png\", dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(16, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(f\"Low-Resolution Input ({lr_patch_size}x{lr_patch_size} patches)\")\n",
    "    lr_test_reconstructed = torch.zeros((3, padded_height // scale_factor, padded_width // scale_factor))\n",
    "    patch_idx = 0\n",
    "    for y in range(0, padded_height, patch_size):\n",
    "        for x in range(0, padded_width, patch_size):\n",
    "            lr_patch = denormalize(test_patches[patch_idx].squeeze(0).cpu())  ### ADDED HERE\n",
    "            lr_test_reconstructed[:, y // scale_factor:(y + patch_size) // scale_factor,\n",
    "                                  x // scale_factor:(x + patch_size) // scale_factor] = lr_patch\n",
    "            patch_idx += 1\n",
    "    lr_test_reconstructed = lr_test_reconstructed[:, :test_height // scale_factor, :test_width // scale_factor]\n",
    "    plt.imshow(transforms.ToPILImage()(lr_test_reconstructed))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(f\"Super-Resolved Output (Epoch {epoch+1})\")\n",
    "    plt.imshow(transforms.ToPILImage()(sr_test_image))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(f\"Original High-Resolution\")\n",
    "    plt.imshow(test_image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"progress_resnet_v9/epoch_{epoch+1}_reconstruction_comparison.png\", dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
